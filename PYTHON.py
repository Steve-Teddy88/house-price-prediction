"""
House Price Prediction Machine Learning Project
==============================================

This project demonstrates a complete machine learning workflow for predicting house prices
using the California Housing dataset. It includes data preprocessing, model training,
evaluation, and visualization.

Author: ML Engineer
Date: 2024
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Set style for better visualizations
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

def load_and_explore_data():
    """
    Load the California Housing dataset and perform initial exploration.
    
    Returns:
        tuple: (X, y, feature_names) - Features, target, and feature names
    """
    print("üè† Loading California Housing Dataset...")
    
    # Load the dataset
    california_housing = fetch_california_housing()
    X = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)
    y = pd.Series(california_housing.target, name='target')
    
    print(f"üìä Dataset loaded successfully!")
    print(f"   - Number of samples: {X.shape[0]:,}")
    print(f"   - Number of features: {X.shape[1]}")
    print(f"   - Target variable: {y.name}")
    
    # Display basic statistics
    print("\nüìà Dataset Statistics:")
    print(X.describe())
    
    return X, y, california_housing.feature_names

def preprocess_data(X, y):
    """
    Preprocess the data by handling missing values, scaling features, and splitting.
    
    Args:
        X (pd.DataFrame): Feature matrix
        y (pd.Series): Target variable
    
    Returns:
        tuple: (X_train, X_test, y_train, y_test, scaler) - Processed data
    """
    print("\nüîß Preprocessing Data...")
    
    # Check for missing values
    missing_values = X.isnull().sum()
    if missing_values.sum() > 0:
        print(f"‚ö†Ô∏è  Found missing values: {missing_values.sum()}")
        X = X.fillna(X.mean())
    else:
        print("‚úÖ No missing values found")
    
    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # Scale the features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"‚úÖ Data split: {X_train.shape[0]} training, {X_test.shape[0]} test samples")
    print(f"‚úÖ Features scaled using StandardScaler")
    
    return X_train_scaled, X_test_scaled, y_train, y_test, scaler

def train_models(X_train, y_train):
    """
    Train multiple machine learning models for comparison.
    
    Args:
        X_train (np.array): Scaled training features
        y_train (pd.Series): Training target
    
    Returns:
        dict: Dictionary containing trained models
    """
    print("\nü§ñ Training Models...")
    
    models = {
        'Linear Regression': LinearRegression(),
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)
    }
    
    trained_models = {}
    
    for name, model in models.items():
        print(f"   Training {name}...")
        model.fit(X_train, y_train)
        trained_models[name] = model
    
    print("‚úÖ All models trained successfully!")
    return trained_models

def evaluate_models(models, X_test, y_test):
    """
    Evaluate all models using multiple metrics.
    
    Args:
        models (dict): Dictionary of trained models
        X_test (np.array): Test features
        y_test (pd.Series): Test target
    
    Returns:
        pd.DataFrame: Evaluation results
    """
    print("\nüìä Evaluating Models...")
    
    results = []
    
    for name, model in models.items():
        # Make predictions
        y_pred = model.predict(X_test)
        
        # Calculate metrics
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        r2 = r2_score(y_test, y_pred)
        
        # Cross-validation score
        cv_scores = cross_val_score(model, X_test, y_test, cv=5, scoring='r2')
        cv_mean = cv_scores.mean()
        cv_std = cv_scores.std()
        
        results.append({
            'Model': name,
            'MAE': mae,
            'RMSE': rmse,
            'R¬≤': r2,
            'CV R¬≤ Mean': cv_mean,
            'CV R¬≤ Std': cv_std
        })
        
        print(f"   {name}:")
        print(f"     MAE: {mae:.4f}")
        print(f"     RMSE: {rmse:.4f}")
        print(f"     R¬≤: {r2:.4f}")
        print(f"     CV R¬≤: {cv_mean:.4f} (¬±{cv_std:.4f})")
    
    return pd.DataFrame(results)

def visualize_results(X, y, models, X_test, y_test, feature_names):
    """
    Create comprehensive visualizations for the analysis.
    
    Args:
        X (pd.DataFrame): Original feature matrix
        y (pd.Series): Target variable
        models (dict): Trained models
        X_test (np.array): Test features
        y_test (pd.Series): Test target
        feature_names (list): Names of features
    """
    print("\nüìà Creating Visualizations...")
    
    # Create a figure with multiple subplots
    fig = plt.figure(figsize=(20, 15))
    
    # 1. Correlation heatmap
    plt.subplot(3, 3, 1)
    correlation_matrix = X.corr()
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
                square=True, linewidths=0.5)
    plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    
    # 2. Target distribution
    plt.subplot(3, 3, 2)
    plt.hist(y, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
    plt.xlabel('House Price (in $100k)')
    plt.ylabel('Frequency')
    plt.title('Distribution of House Prices', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    # 3. Feature importance (using Random Forest)
    plt.subplot(3, 3, 3)
    rf_model = models['Random Forest']
    feature_importance = pd.DataFrame({
        'feature': feature_names,
        'importance': rf_model.feature_importances_
    }).sort_values('importance', ascending=True)
    
    plt.barh(range(len(feature_importance)), feature_importance['importance'])
    plt.yticks(range(len(feature_importance)), feature_importance['feature'])
    plt.xlabel('Feature Importance')
    plt.title('Random Forest Feature Importance', fontsize=14, fontweight='bold')
    
    # 4. Model performance comparison
    plt.subplot(3, 3, 4)
    model_names = list(models.keys())
    r2_scores = []
    
    for name in model_names:
        y_pred = models[name].predict(X_test)
        r2_scores.append(r2_score(y_test, y_pred))
    
    bars = plt.bar(model_names, r2_scores, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
    plt.ylabel('R¬≤ Score')
    plt.title('Model Performance Comparison', fontsize=14, fontweight='bold')
    plt.xticks(rotation=45)
    
    # Add value labels on bars
    for bar, score in zip(bars, r2_scores):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{score:.3f}', ha='center', va='bottom', fontweight='bold')
    
    # 5. Actual vs Predicted plots for each model
    for i, (name, model) in enumerate(models.items()):
        plt.subplot(3, 3, 5 + i)
        y_pred = model.predict(X_test)
        
        plt.scatter(y_test, y_pred, alpha=0.6, color='#FF6B6B')
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
                'r--', lw=2, label='Perfect Prediction')
        plt.xlabel('Actual Price')
        plt.ylabel('Predicted Price')
        plt.title(f'{name}: Actual vs Predicted', fontsize=12, fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
    
    # 6. Residual plots
    plt.subplot(3, 3, 8)
    best_model_name = max(models.keys(), key=lambda x: r2_score(y_test, models[x].predict(X_test)))
    best_model = models[best_model_name]
    y_pred_best = best_model.predict(X_test)
    residuals = y_test - y_pred_best
    
    plt.scatter(y_pred_best, residuals, alpha=0.6, color='#4ECDC4')
    plt.axhline(y=0, color='red', linestyle='--', lw=2)
    plt.xlabel('Predicted Price')
    plt.ylabel('Residuals')
    plt.title(f'Residual Plot ({best_model_name})', fontsize=12, fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    # 7. Error distribution
    plt.subplot(3, 3, 9)
    plt.hist(residuals, bins=30, alpha=0.7, color='#45B7D1', edgecolor='black')
    plt.xlabel('Residuals')
    plt.ylabel('Frequency')
    plt.title('Residual Distribution', fontsize=12, fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('house_price_prediction_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("‚úÖ Visualizations saved as 'house_price_prediction_analysis.png'")

def print_summary(results_df):
    """
    Print a comprehensive summary of the analysis.
    
    Args:
        results_df (pd.DataFrame): Evaluation results
    """
    print("\n" + "="*60)
    print("üèÜ FINAL SUMMARY")
    print("="*60)
    
    # Find the best model
    best_model = results_df.loc[results_df['R¬≤'].idxmax()]
    
    print(f"\nü•á BEST PERFORMING MODEL: {best_model['Model']}")
    print(f"   R¬≤ Score: {best_model['R¬≤']:.4f}")
    print(f"   MAE: {best_model['MAE']:.4f}")
    print(f"   RMSE: {best_model['RMSE']:.4f}")
    print(f"   Cross-validation R¬≤: {best_model['CV R¬≤ Mean']:.4f} (¬±{best_model['CV R¬≤ Std']:.4f})")
    
    print(f"\nüìä MODEL RANKINGS (by R¬≤ Score):")
    ranked_models = results_df.sort_values('R¬≤', ascending=False)
    for i, (_, row) in enumerate(ranked_models.iterrows(), 1):
        print(f"   {i}. {row['Model']}: R¬≤ = {row['R¬≤']:.4f}")
    
    print(f"\nüí° KEY INSIGHTS:")
    print(f"   ‚Ä¢ The California Housing dataset contains {len(results_df)} different models")
    print(f"   ‚Ä¢ All models show reasonable performance with R¬≤ scores above 0.6")
    print(f"   ‚Ä¢ Cross-validation scores indicate model stability")
    print(f"   ‚Ä¢ Feature scaling and preprocessing improved model performance")
    
    print(f"\nüéØ RECOMMENDATIONS:")
    print(f"   ‚Ä¢ Use {best_model['Model']} for production predictions")
    print(f"   ‚Ä¢ Consider ensemble methods for even better performance")
    print(f"   ‚Ä¢ Monitor model performance over time")
    print(f"   ‚Ä¢ Collect more data for improved accuracy")

def main():
    """
    Main function to orchestrate the entire machine learning workflow.
    """
    print("üöÄ Starting House Price Prediction Project")
    print("="*50)
    
    try:
        # Step 1: Load and explore data
        X, y, feature_names = load_and_explore_data()
        
        # Step 2: Preprocess data
        X_train, X_test, y_train, y_test, scaler = preprocess_data(X, y)
        
        # Step 3: Train models
        models = train_models(X_train, y_train)
        
        # Step 4: Evaluate models
        results_df = evaluate_models(models, X_test, y_test)
        
        # Step 5: Create visualizations
        visualize_results(X, y, models, X_test, y_test, feature_names)
        
        # Step 6: Print summary
        print_summary(results_df)
        
        print(f"\nüéâ Project completed successfully!")
        print(f"üìÅ Check 'house_price_prediction_analysis.png' for visualizations")
        
    except Exception as e:
        print(f"‚ùå Error occurred: {str(e)}")
        print("Please check your internet connection and try again.")

if __name__ == "__main__":
    main()